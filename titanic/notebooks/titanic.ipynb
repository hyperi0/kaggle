{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_all = pd.read_csv(\"../data/train.csv\")\n",
    "test_data_all = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values in training data\n",
    "\n",
    "def filter_df(df):\n",
    "\n",
    "    df_filtered = pd.DataFrame()\n",
    "\n",
    "    for column in df.columns:\n",
    "        dtype = df[column].dtype\n",
    "\n",
    "        # use -1 for numerical data, \"NA\" for strings (objects)\n",
    "        if dtype == \"int64\" or dtype == \"float64\":\n",
    "            val = -1\n",
    "        else:\n",
    "            val = \"NA\"\n",
    "        df[column] = df[column].fillna(val)\n",
    "\n",
    "    # ignore name, and ticket (for now)\n",
    "    df_filtered = df.drop(columns=[\"Name\", \"Ticket\"])\n",
    "\n",
    "    # convert age to float for treatment as continuous variable\n",
    "    df_filtered[\"Age\"] = df_filtered[\"Age\"].astype('float64')\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_filtered = filter_df(train_data_all).drop(columns=\"PassengerId\")\n",
    "\n",
    "test_data_filtered = filter_df(test_data_all)\n",
    "test_ids = test_data_filtered.pop(\"PassengerId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and validation datasets\n",
    "\n",
    "val_frac = .2\n",
    "val_df = train_data_filtered.sample(frac=0.2)\n",
    "train_df = train_data_filtered.drop(val_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pd DataFrame to tf Dataset labelled with answers\n",
    "def dataframe_to_dataset(df):\n",
    "    \n",
    "    df = df.copy()\n",
    "    labels = df.pop(\"Survived\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(df))\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to Datasets\n",
    "train_ds = dataframe_to_dataset(train_df)\n",
    "val_ds = dataframe_to_dataset(val_df)\n",
    "\n",
    "# batch Datasets\n",
    "batch_size = 32\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "val_ds = val_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert test data\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(dict(test_data_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import StringLookup\n",
    "\n",
    "def encode_string_feature(feature, name, feature_ds):\n",
    "\n",
    "    lookup = StringLookup(output_mode=\"one_hot\")\n",
    "    lookup.adapt(feature_ds)\n",
    "\n",
    "    return lookup(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import IntegerLookup\n",
    "\n",
    "def encode_integer_feature(feature, name, feature_ds):\n",
    "\n",
    "    lookup = IntegerLookup(output_mode=\"one_hot\")\n",
    "    lookup.adapt(feature_ds)\n",
    "\n",
    "    return lookup(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Normalization\n",
    "\n",
    "def encode_float_feature(feature, name, feature_ds):\n",
    "\n",
    "    normalizer = Normalization()\n",
    "    normalizer.adapt(feature_ds)\n",
    "    \n",
    "    return normalizer(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_feature(feature, name, dataset):\n",
    "\n",
    "    # construct dataset with only given feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # build encoder based on feature dtype\n",
    "    dtype = feature_ds.element_spec.dtype\n",
    "\n",
    "    if dtype == tf.string:\n",
    "        encoded_feature = encode_string_feature(feature, name, feature_ds)\n",
    "    elif dtype == tf.int64:\n",
    "        encoded_feature = encode_integer_feature(feature, name, feature_ds)\n",
    "    elif dtype == tf.float64:\n",
    "        encoded_feature = encode_float_feature(feature, name, feature_ds)\n",
    "    else:\n",
    "        print(\"Unexpected datatype: \" + str(dtype))\n",
    "        encoded_feature = \"AAAAaaaAA\"\n",
    "\n",
    "    return encoded_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build input layers based on feature specs from ds\n",
    "\n",
    "all_inputs = dict()\n",
    "\n",
    "features = train_ds.element_spec[0]\n",
    "\n",
    "for name, spec in features.items():\n",
    "    all_inputs[name] = keras.Input(\n",
    "        shape=(1,),\n",
    "        name=name,\n",
    "        dtype=spec.dtype\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 16:35:41.139577: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# build individual encoding layers for each feature\n",
    "\n",
    "encodings = dict()\n",
    "\n",
    "for name, spec in features.items():\n",
    "    encodings[name] = encode_feature(\n",
    "        all_inputs[name],\n",
    "        name,\n",
    "        train_ds\n",
    "    )\n",
    "\n",
    "# concatenate feature encodings\n",
    "\n",
    "all_features = layers.concatenate(encodings.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dense network from encoded features to predicted survival\n",
    "\n",
    "x = layers.Dense(128, activation=\"relu\")(all_features)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "\n",
    "inputs = list(all_inputs.values())\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs, output)\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6304 - accuracy: 0.6690\n",
      "Epoch 2/3\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7630\n",
      "Epoch 3/3\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.4727 - accuracy: 0.7910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17ef0ab60>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "model.fit(train_ds, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 0.5726 - accuracy: 0.6875"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Save or restore weights that is not an instance of `tf.Variable` is not supported in h5, use `save_format='tf'` instead. Received a model or layer IntegerLookup with weights [<keras.layers.preprocessing.index_lookup.VocabWeightHandler object at 0x17ef0b970>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m best_model_callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(best_model_path, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mbest_model_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load the best model\u001b[39;00m\n\u001b[1;32m      9\u001b[0m best_model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(best_model_path)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/keras/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/keras/lib/python3.10/site-packages/keras/saving/hdf5_format.py:1111\u001b[0m, in \u001b[0;36m_legacy_weights\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m   1109\u001b[0m weights \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mtrainable_weights \u001b[38;5;241m+\u001b[39m layer\u001b[38;5;241m.\u001b[39mnon_trainable_weights\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(w, tf\u001b[38;5;241m.\u001b[39mVariable) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m weights):\n\u001b[0;32m-> 1111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1112\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSave or restore weights that is not an instance of `tf.Variable` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1113\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not supported in h5, use `save_format=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` instead. Received \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1114\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma model or layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1115\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith weights \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1116\u001b[0m     )\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m weights\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Save or restore weights that is not an instance of `tf.Variable` is not supported in h5, use `save_format='tf'` instead. Received a model or layer IntegerLookup with weights [<keras.layers.preprocessing.index_lookup.VocabWeightHandler object at 0x17ef0b970>]"
     ]
    }
   ],
   "source": [
    "# Create callback to save the best model\n",
    "best_model_path = \"best_model.h5\"\n",
    "best_model_callback = tf.keras.callbacks.ModelCheckpoint(best_model_path, monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_ds, epochs=10, validation_data=val_ds, callbacks=[best_model_callback])\n",
    "\n",
    "# Load the best model\n",
    "best_model = tf.keras.models.load_model(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.8275 - val_loss: 0.4475 - val_accuracy: 0.8146\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4117 - accuracy: 0.8303 - val_loss: 0.4477 - val_accuracy: 0.8146\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8513 - val_loss: 0.4463 - val_accuracy: 0.8034\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3759 - accuracy: 0.8597 - val_loss: 0.4456 - val_accuracy: 0.8034\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.8626 - val_loss: 0.4431 - val_accuracy: 0.8202\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3608 - accuracy: 0.8626 - val_loss: 0.4449 - val_accuracy: 0.8202\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3584 - accuracy: 0.8682 - val_loss: 0.4435 - val_accuracy: 0.8146\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8724 - val_loss: 0.4400 - val_accuracy: 0.8258\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8794 - val_loss: 0.4427 - val_accuracy: 0.8258\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3435 - accuracy: 0.8724 - val_loss: 0.4463 - val_accuracy: 0.8090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Pclass, Sex, Age, SibSp, Parch, Fare, Cabin, Embarked with unsupported characters which will be renamed to pclass, sex, age, sibsp, parch, fare, cabin, embarked in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_epoch_8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_epoch_8/assets\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=10, validation_data=val_ds)\n",
    "\n",
    "# Get the epoch with the best validation accuracy\n",
    "best_epoch = np.argmax(history.history['val_accuracy']) + 1\n",
    "\n",
    "# Save the model with the best validation accuracy\n",
    "model.save('best_model_epoch_{}'.format(best_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.data.Dataset.from_tensor_slices(dict(test_data_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 652us/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(dict(test_data_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_predictions = pd.DataFrame()\n",
    "labelled_predictions[\"PassengerId\"] = test_ids\n",
    "labelled_predictions[\"Survived\"] = [round(pred[0]) for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_predictions.to_csv(\"../submissions/deep_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
